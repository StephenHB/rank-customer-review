{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import subprocess\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"downloading...\")\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/stephenzhang/Downloads/yelp.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract dish names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_verbs(df, col_name, top_n_verbs=30):\n",
    "    text_data_list = df[col_name].tolist()\n",
    "    verbs = []\n",
    "    for doc in nlp.pipe(text_data_list):\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"VERB\" and token.dep_ in (\"ROOT\", \"dobj\"):\n",
    "                verbs.append(token.lemma_)\n",
    "        action_verbs = set([v for v, cnt in Counter(verbs).most_common(top_n_verbs)])\n",
    "        \n",
    "    return action_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_menu_items(df, col_name, top_n_menu_items=100):\n",
    "    text_data_list = df[col_name].tolist()\n",
    "    menu_candidates = []\n",
    "    for doc in nlp.pipe(text_data_list):\n",
    "        for chunk in doc.noun_chunks:\n",
    "            if len(chunk.text.split()) >= 2:  # 提取复合名词\n",
    "                menu_candidates.append(chunk.text.lower())\n",
    "    menu_items = set([item for item, cnt in Counter(menu_candidates).most_common(100)])\n",
    "    return menu_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_clean\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_VERBS = get_action_verbs(df, 'text_clean', 20)\n",
    "menu_items = get_action_verbs(df, 'text_clean', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_dish(dish):\n",
    "    doc = nlp(dish)\n",
    "    return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dishes_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    dishes = []\n",
    "    \n",
    "    # 规则1：通过动词的直接宾语提取\n",
    "    for token in doc:\n",
    "        if token.text.lower() in ACTION_VERBS and token.dep_ == \"ROOT\":\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"dobj\":  # 直接宾语\n",
    "                    dish = \" \".join([w.lemma_ for w in child.subtree])\n",
    "                    dishes.append(dish)\n",
    "    \n",
    "    # 规则2：名词短语（过滤短短语）\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if len(chunk.text.split()) >= 2:\n",
    "            dish = \" \".join([w.lemma_ for w in chunk])\n",
    "            dishes.append(dish)\n",
    "    \n",
    "    return list(set(dishes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dishes_spacy(texts, min_freq=2):\n",
    "    all_dishes = []\n",
    "    for text in texts:\n",
    "        dishes = extract_dishes_spacy(text)\n",
    "        # 过滤停用词和通用词\n",
    "        stop_words = {\"food\", \"service\", \"restaurant\", \"place\"}\n",
    "        filtered = [\n",
    "            dish for dish in dishes\n",
    "            if not any(word in dish.split() for word in stop_words)\n",
    "        ]\n",
    "        all_dishes.extend(filtered)\n",
    "    \n",
    "    # 统计高频词\n",
    "    counter = Counter(all_dishes)\n",
    "    return [dish for dish, freq in counter.items() if freq >= min_freq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_spacy_to_df(df, filter_validate_menue=False):    \n",
    "    # 提取菜品并词形还原\n",
    "    df[\"dishes_raw\"] = df[\"text_clean\"].apply(extract_dishes_spacy)\n",
    "    df[\"dishes_lemmatized\"] = df[\"dishes_raw\"].apply(\n",
    "        lambda dishes: [lemmatize_dish(dish) for dish in dishes]\n",
    "    )\n",
    "    if filter_validate_menue:\n",
    "        df[\"valid_dishes\"] = df[\"dishes_lemmatized\"].apply(\n",
    "            lambda dishes: [dish for dish in dishes if dish in menu_items]\n",
    "        )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = apply_spacy_to_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>dishes_raw</th>\n",
       "      <th>dishes_lemmatized</th>\n",
       "      <th>valid_dishes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>[a favor, the place, an absolute pleasure, our...</td>\n",
       "      <td>[a favor, the place, an absolute pleasure, our...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>[all these bad reviewer, the beef pizza, many ...</td>\n",
       "      <td>[all these bad reviewer, the beef pizza, many ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love the gyro plate rice is so good and i also...</td>\n",
       "      <td>[their candy selection, the gyro plate rice]</td>\n",
       "      <td>[their candy selection, the gyro plate rice]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>rosie dakota and i love chaparral dog park its...</td>\n",
       "      <td>[trash can, the dog, a lake, the park, a wonde...</td>\n",
       "      <td>[trash can, the dog, a lake, the park, a wonde...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>general manager scott petello is a good egg no...</td>\n",
       "      <td>[his awesome staff, a customer, your case, a g...</td>\n",
       "      <td>[his awesome staff, a customer, your case, a g...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \\\n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0   \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0   \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0   \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0   \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  my wife took me here on my birthday for breakf...   \n",
       "1  i have no idea why some people give bad review...   \n",
       "2  love the gyro plate rice is so good and i also...   \n",
       "3  rosie dakota and i love chaparral dog park its...   \n",
       "4  general manager scott petello is a good egg no...   \n",
       "\n",
       "                                          dishes_raw  \\\n",
       "0  [a favor, the place, an absolute pleasure, our...   \n",
       "1  [all these bad reviewer, the beef pizza, many ...   \n",
       "2       [their candy selection, the gyro plate rice]   \n",
       "3  [trash can, the dog, a lake, the park, a wonde...   \n",
       "4  [his awesome staff, a customer, your case, a g...   \n",
       "\n",
       "                                   dishes_lemmatized valid_dishes  \n",
       "0  [a favor, the place, an absolute pleasure, our...           []  \n",
       "1  [all these bad reviewer, the beef pizza, many ...           []  \n",
       "2       [their candy selection, the gyro plate rice]           []  \n",
       "3  [trash can, the dog, a lake, the park, a wonde...           []  \n",
       "4  [his awesome staff, a customer, your case, a g...           []  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
